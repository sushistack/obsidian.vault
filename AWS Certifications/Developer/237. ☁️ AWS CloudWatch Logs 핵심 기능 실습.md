
## 📝 CloudWatch Logs 소개 및 기본 구조

**AWS CloudWatch Logs**는 다양한 AWS 서비스와 애플리케이션의 로그를 중앙 집중식으로 관리하고 모니터링하는 데 사용되는 강력한 도구입니다. 로그는 논리적인 구조를 가지고 있으며, 크게 **로그 그룹(Log Group)**과 **로그 스트림(Log Stream)**으로 나뉩니다.

- **로그 그룹**: 특정 애플리케이션, 서비스, 또는 기능에 대한 모든 로그를 담는 컨테이너입니다.
    - **예시**: `SSM-run-command-log-group`은 SSM `runCommand`의 출력 로그를 저장합니다.

- **로그 스트림**: 로그 그룹 내에서 특정 인스턴스, 파일, 컨테이너 등의 로그 이벤트를 구분합니다.
    
    - **예시**: `i-1a2b3c4d/stdout`과 `i-1a2b3c4d/stderr`는 동일한 인스턴스의 표준 출력(stdout)과 표준 에러(stderr) 로그를 각각 나타냅니다.


## 🕵️‍♂️ 로그 데이터 검색 및 분석

CloudWatch Logs 콘솔에서 로그를 탐색할 때, 단순히 키워드를 입력하여 로그를 검색할 수 있습니다. 예를 들어, `http` 또는 `installing`과 같은 키워드로 특정 로그 라인을 쉽게 찾을 수 있습니다.

### CloudWatch Logs Insights

Logs Insights는 CloudWatch Logs의 강력한 쿼리 엔진으로, SQL과 유사한 쿼리 언어를 사용하여 저장된 로그를 분석하고 인사이트를 얻을 수 있게 해줍니다.

**주요 기능**:

- **복잡한 쿼리**: `filter`, `stats`, `fields` 등을 사용해 원하는 데이터를 정밀하게 추출할 수 있습니다.
- **기간 설정**: 특정 시간 범위(`Past 1 hour`, `Past 60 days` 등)의 데이터를 대상으로 쿼리할 수 있습니다.
- **시각화**: 쿼리 결과를 시각화하여 데이터의 패턴을 쉽게 파악할 수 있습니다.
- **템플릿 쿼리**: Lambda, VPC Flow Logs 등 특정 서비스에 대한 자주 사용되는 쿼리 템플릿을 제공하여 사용자가 쉽게 시작할 수 있도록 돕습니다.

예시 쿼리:

특정 로그 그룹에서 지난 60일 동안 발생한 로그 이벤트를 모두 검색하는 쿼리입니다.

```SQL
fields @timestamp, @message
| sort @timestamp desc
| limit 20
```

이 쿼리를 실행하면 필터링된 로그 이벤트를 확인하고, 이를 통해 문제 해결에 필요한 정보를 얻을 수 있습니다.

---

## 🔔 로그 기반 지표 및 경보 설정

CloudWatch Logs의 **지표 필터(Metric Filter)**를 사용하면 특정 패턴의 로그 이벤트를 감지하여 CloudWatch 지표(Metric)로 변환할 수 있습니다. 이 지표를 기반으로 경보(Alarm)를 설정하여 자동으로 알림을 받거나 작업을 수행하도록 구성할 수 있습니다.

**지표 필터 생성 단계**:

1. **필터 패턴 정의**: 로그에서 찾고자 하는 특정 키워드나 패턴을 지정합니다.
    - **예시**: `installing`이라는 키워드를 찾기 위한 패턴입니다.

2. **지표 이름 및 네임스페이스 지정**: 새 지표의 이름(`DemoMetric`)과 네임스페이스(`DemoMetricFilterNamespace`)를 정의합니다.
    
3. **지표 값 설정**: 필터 패턴이 일치할 때마다 지표에 추가될 값을 설정합니다.
    - **예시**: `1`로 설정하면, `installing` 키워드가 발견될 때마다 지표 값이 1씩 증가합니다.

4. **경보 설정**: 생성된 지표를 기반으로 특정 임계값(Threshold)을 초과할 경우 경보가 울리도록 구성합니다.


이 기능을 활용하면 로그를 지속적으로 모니터링하지 않고도 중요한 이벤트(예: 오류 발생, 특정 작업 완료)를 놓치지 않고 대응할 수 있습니다.

---

## 🚚 로그 데이터 관리 및 내보내기

### 보존 정책 (Retention Policy)

로그 그룹의 **보존 정책**을 설정하여 로그를 얼마나 오래 저장할지 결정할 수 있습니다.

- **기간 설정**: `Never Expire`(무기한)부터 1일, 30일, 1년, 최대 10년까지 다양한 기간을 선택할 수 있습니다.

### S3로 데이터 내보내기 (Export Data)

**로그 데이터 내보내기** 기능을 사용하여 특정 기간의 로그를 S3 버킷으로 대량으로 옮길 수 있습니다. 이는 장기간 보관이나 추가적인 분석을 위해 로그 데이터를 아카이빙할 때 유용합니다.

**설정 항목**:

- **기간**: 내보내기를 원하는 로그 데이터의 시작 및 종료 시간을 선택합니다.
- **로그 스트림 접두사**: 특정 로그 스트림만 내보내고 싶을 때 사용합니다.
- **S3 버킷**: 로그를 저장할 S3 버킷을 지정합니다.

### 구독 필터 (Subscription Filter)

**구독 필터**를 사용하면 로그 이벤트를 실시간으로 스트리밍하여 다른 AWS 서비스로 보낼 수 있습니다. 이 기능은 로그를 실시간으로 처리하고 분석하는 데 필수적입니다.

**지원 대상**:

- **Amazon Kinesis Data Streams**: 실시간 데이터 스트리밍 및 처리에 적합합니다.
- **Amazon Kinesis Data Firehose**: S3, Amazon OpenSearch Service 등으로 데이터를 쉽게 전송합니다.
- **AWS Lambda**: 로그 데이터를 사용자 지정 함수로 보내 실시간으로 처리할 수 있습니다.

로그 그룹당 최대 두 개의 구독 필터를 설정할 수 있습니다.

---

## 🔒 로그 그룹 생성 및 암호화

사용자는 필요에 따라 새로운 로그 그룹을 직접 생성할 수 있습니다. 로그 그룹 생성 시 **KMS(Key Management Service)** 키를 지정하여 저장되는 로그 데이터를 암호화할 수 있습니다. 이는 민감한 정보를 포함하는 로그에 대해 추가적인 보안 계층을 제공합니다.

|설정 항목|설명|
|---|---|
|**로그 그룹 이름**|로그 그룹을 식별하는 고유한 이름|
|**보존 기간**|로그를 보관할 기간|
|**KMS 키**|로그를 암호화할 KMS 키 ID (선택 사항)|