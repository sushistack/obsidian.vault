
Amazon Athena는 AWS S3에 저장된 데이터를 **SQL**로 직접 분석할 수 있는 강력한 서버리스 서비스입니다. 이 가이드에서는 Athena를 사용하여 S3의 Access Log를 쿼리하고 분석하는 실습 과정을 상세히 안내합니다. 이를 통해 Athena의 효율성과 편리함을 직접 경험할 수 있습니다.

---

## 1. ⚙️ 사전 설정: 쿼리 결과 저장소 구성

Athena는 쿼리 결과를 S3 버킷에 저장합니다. 첫 쿼리를 실행하기 전에, 이 결과를 저장할 버킷을 지정해야 합니다.

1. **S3 버킷 생성**: S3 콘솔에서 Athena 쿼리 결과를 저장할 버킷을 새로 생성합니다. 버킷 이름은 전역적으로 고유해야 합니다.
    - **예시**: `aws-athena-stephane-eu-central-1-v2`

2. **Athena 설정**: Athena 쿼리 편집기에서 **`Settings`** > **`Manage`** > **`S3 location for query result`**로 이동합니다.
    
3. **버킷 경로 입력**: 생성한 S3 버킷의 경로(예: `s3://aws-athena-stephane-eu-central-1-v2/`)를 입력하고 저장합니다.
    

---

## 2. 📋 데이터베이스 및 테이블 생성

Athena에서 S3의 데이터를 쿼리하려면, 먼저 S3 버킷 내의 데이터를 나타내는 **데이터베이스**와 **테이블**을 정의해야 합니다.

### 단계 1: 데이터베이스 생성

쿼리 편집기에서 `CREATE DATABASE` 명령어를 실행하여 데이터베이스를 생성합니다.

```SQL
CREATE DATABASE s3_access_logs_db;
```

- **결과**: 좌측 패널에 `s3_access_logs_db`라는 새로운 데이터베이스가 생성됩니다.
    

### 단계 2: S3 Access Log 테이블 생성

S3 Access Log는 특정 형식을 따릅니다. Athena는 이 형식을 이해할 수 있도록 테이블 스키마를 정의해야 합니다. AWS 문서에서 제공하는 템플릿을 사용하여 테이블을 생성할 수 있습니다.

- **`LOCATION`**: `LOCATION` 속성에 쿼리할 S3 버킷의 경로를 정확하게 입력합니다.
    
- **스키마 정의**: 로그의 각 필드(버킷 소유자, 요청 시간, IP 주소 등)에 대한 컬럼 이름과 데이터 타입을 정의합니다.

```SQL
CREATE EXTERNAL TABLE s3_access_logs_table (
  bucketowner STRING,
  bucket_name STRING,
  requestdatetime STRING,
  remoteip STRING,
  requester STRING,
  requestid STRING,
  operation STRING,
  key STRING,
  requesturi_operation STRING,
  requesturi_key STRING,
  requesturi_httpprotocol STRING,
  httpstatus INT,
  errorcode STRING,
  bytessent BIGINT,
  objectsize BIGINT,
  totaltime BIGINT,
  turnaroundtime BIGINT,
  referrer STRING,
  useragent STRING,
  versionid STRING
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe'
WITH SERDEPROPERTIES (
'input.regex' = '([0-9a-zA-Z\\.\\-]*)\\s([^ ]*)\\s\\[([^\\]]*)\\]\\s([^ ]*)\\s([^ ]*)\\s([^ ]*)\\s([^ ]*)\\s([^ ]*)\\s("[^"]*")\\s(\\d*)\\s([^ ]*)\\s([^ ]*)\\s([^ ]*)\\s([^ ]*)\\s([^ ]*)\\s([^ ]*)\\s("[^"]*")\\s("[^"]*")\\s([^ ]*)'
)
LOCATION 's3://your-access-log-bucket-name/';
```

- **결과**: `s3_access_logs_table`이 `s3_access_logs_db` 데이터베이스에 추가됩니다.

---

## 3. 🚀 데이터 쿼리 및 분석

이제 S3 버킷의 데이터를 SQL 쿼리로 직접 분석할 수 있습니다.

### 예시 1: 테이블 미리보기

`PREVIEW` 기능을 사용하여 테이블의 첫 10개 행을 빠르게 확인할 수 있습니다.

- **콘솔**: 테이블 이름 옆의 세 점 아이콘을 클릭하고 **`Preview table`**을 선택합니다.
    
- **결과**: SQL 쿼리 결과로 S3 로그 데이터의 일부를 즉시 확인할 수 있습니다.

### 예시 2: 집계 쿼리

SQL의 강력한 기능을 사용하여 로그 데이터에 대한 통계 분석을 수행할 수 있습니다. 예를 들어, HTTP 상태 코드별로 요청 횟수를 집계하는 쿼리입니다.

```SQL
SELECT httpstatus, COUNT(*) AS total_requests
FROM s3_access_logs_table
GROUP BY httpstatus
ORDER BY total_requests DESC;
```

- **결과**: `200(OK)`, `403(Unauthorized)`, `404(Not Found)` 등 HTTP 상태 코드별로 요청 수를 한눈에 볼 수 있습니다. 이 분석을 통해 비정상적인 접근 시도(403)나 깨진 링크(404)를 쉽게 파악할 수 있습니다.

---

## 4. 🌟 결론

Athena는 데이터 이동이나 인스턴스 관리 없이 S3에 저장된 대용량 데이터를 효율적으로 분석하는 강력한 도구입니다. 이 실습을 통해, 몇 가지 간단한 설정과 SQL 쿼리만으로도 복잡한 로그 데이터에서 유의미한 인사이트를 얻을 수 있음을 확인했습니다. 이는 Athena가 데이터 분석을 위한 가장 쉽고 경제적인 AWS 서비스 중 하나임을 보여줍니다.