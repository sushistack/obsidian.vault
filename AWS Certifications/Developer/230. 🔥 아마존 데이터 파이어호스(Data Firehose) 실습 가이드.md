
## 🏗️ 딜리버리 스트림 생성

### 1. 소스 및 목적지 선택

- **소스(Source):** 데이터를 어디서 가져올지 선택합니다. 파이어호스는 키네시스 데이터 스트림, 직접 Put, AWS 서비스 등 다양한 소스를 지원합니다.
    - **실습:** 이전에 생성한 **키네시스 데이터 스트림(`DemoStream`)**을 소스로 선택합니다.
    
- **목적지(Destination):** 데이터를 어디로 보낼지 선택합니다. 파이어호스는 S3, OpenSearch Service, Redshift 등을 지원합니다.
    - **실습:** **아마존 S3**를 목적지로 선택합니다.

### 2. 데이터 변환 및 형식 변환 설정 (선택 사항)

- **Lambda를 통한 변환:** Lambda 함수를 사용하여 데이터를 변환, 필터링, 압축 해제, 형식 변경 등을 할 수 있습니다. (실습에서는 사용하지 않음)

- **레코드 형식 변환:** 데이터를 Parquet 또는 ORC와 같은 분석 친화적인 형식으로 변환할 수 있습니다. (실습에서는 사용하지 않음)


### 3. 목적지 및 버퍼 설정

- **S3 버킷:** 데이터를 저장할 S3 버킷을 지정합니다. (예: `demo-firehose-stephane-V3`)
    
- **버퍼(Buffer):** 파이어호스는 실시간 데이터를 버퍼에 모아두었다가 목적지로 한 번에 전달합니다.
    
    - **버퍼 크기:** 버퍼링할 데이터의 크기를 메가바이트(MB) 단위로 설정합니다. 기본값은 5MB입니다. (실습에서는 1MB로 설정)

    - **버퍼 간격:** 버퍼가 가득 차지 않더라도 데이터를 전달할 최대 시간을 초 단위로 설정합니다. 기본값은 300초(5분)입니다. (실습에서는 **60초**로 설정하여 빠르게 결과를 확인)

- **압축 및 암호화:**
    - **압축:** GZIP, Snappy 등의 압축 방식을 설정하여 S3 스토리지 비용을 절감할 수 있습니다.
    - **암호화:** 데이터를 암호화하여 저장할 수 있습니다.
        
- **IAM 역할:** 파이어호스가 키네시스 데이터 스트림에서 데이터를 읽고 S3 버킷에 쓸 수 있도록 필요한 권한을 가진 **IAM 역할**이 자동으로 생성됩니다.
    

---

## 🧪 스트림 테스트

### 1. 데이터 파이어호스 생성 및 상태 확인

- `Create delivery stream`을 클릭하여 딜리버리 스트림을 생성합니다. 스트림이 `Active` 상태가 될 때까지 기다립니다.

### 2. 키네시스 데이터 스트림에 데이터 전송

- 데이터 파이어호스는 새로운 데이터가 스트림으로 들어올 때만 작동합니다. 따라서 이전에 사용했던 키네시스 데이터 스트림에 새로운 데이터를 전송해야 합니다.
- **AWS CloudShell**을 사용하여 `put-record` 명령어로 `user signup`, `user login`, `user logout` 메시지를 전송합니다.

### 3. S3 버킷에 데이터 전달 확인

- 파이어호스의 버퍼 간격이 60초이므로, S3 버킷에 데이터가 나타나기까지 **최대 60초**가 소요됩니다.
- 60초 후 S3 버킷을 확인하면, 날짜 및 시간별로 정리된 폴더가 생성되어 있고, 그 안에 텍스트 파일이 저장된 것을 볼 수 있습니다.
- 파일을 열어보면 전송했던 `user signup`, `user login`, `user logout` 메시지들이 한 파일에 기록되어 있습니다.

이 실습을 통해 키네시스 데이터 스트림에서 생성된 데이터가 파이어호스의 버퍼링 과정을 거쳐 S3 버킷에 효율적으로 저장되는 과정을 직접 확인할 수 있습니다.

### ⚠️ 중요: 리소스 정리

- 불필요한 비용 발생을 막기 위해 실습 후 **키네시스 데이터 파이어호스 딜리버리 스트림**과 **키네시스 데이터 스트림**을 반드시 삭제해야 합니다.